{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f62e112-7151-4148-8607-aba3b77f6f50",
   "metadata": {},
   "source": [
    "## Importing Necessary Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae2a647-6cf8-4ba2-84f4-da37bb9ef0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c711e2-7d1b-4069-9981-e92151ee699c",
   "metadata": {},
   "source": [
    "## Loading the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776acfe6-66bf-430d-bf97-fa171a781c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'overall', 'verified', 'reviewTime', 'reviewerID', 'asin',\n",
      "       'style', 'reviewerName', 'reviewText', 'summary', 'unixReviewTime',\n",
      "       'vote', 'image'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size = 10000\n",
    "chunks = pd.read_csv(\"C:\\\\Users\\\\srile\\\\Downloads\\\\aws_review_sofware_dataset.csv\", sep=',', chunksize=chunk_size)\n",
    "\n",
    "# Get the first chunk and access its columns\n",
    "df = next(chunks)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d799dc4-abe6-419b-94bb-81bdd2564a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'overall', 'verified', 'reviewTime', 'reviewerID', 'asin',\n",
       "       'style', 'reviewerName', 'reviewText', 'summary', 'unixReviewTime',\n",
       "       'vote', 'image'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be5a623-4d0b-4539-879e-d7dfb3621e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"words\"]=\"default value\"\n",
    "df[\"sentences\"]=\"default value\"\n",
    "\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    df.at[i,\"words\"]= list(\"\")\n",
    "    df.at[i,\"sentences\"] = list(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234078aa-012d-4b0b-9d53-22a486568d4c",
   "metadata": {},
   "source": [
    "## Importing sent Tokenize from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1532fb11-d861-4061-b67e-db3fce17eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ea0bdf6-dc2d-413c-bec1-d5ecec8eea4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\srile\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aeb9cd1-5e3d-4f4d-a71f-3135a6902ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(499):\n",
    "    l1= sent_tokenize(df.loc[i,\"reviewText\"])\n",
    "    df.at[i,\"sentences\"]=l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76620be4-867d-4b79-ba48-2a70561ba3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pywsd in c:\\users\\srile\\appdata\\roaming\\python\\python312\\site-packages (1.2.5)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (from pywsd) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from pywsd) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from pywsd) (2.2.2)\n",
      "Requirement already satisfied: wn==0.0.23 in c:\\users\\srile\\appdata\\roaming\\python\\python312\\site-packages (from pywsd) (0.0.23)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from pywsd) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->pywsd) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->pywsd) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->pywsd) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->pywsd) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->pywsd) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->pywsd) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->pywsd) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk->pywsd) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pywsd library is a tool for resolving word ambiguity in NLP\n",
    "!pip install pywsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "937b487a-8547-46c7-b35c-5955e0726bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\srile\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing averaged_perceptron_tagger finding POS_tagging\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73ff1ac9-612d-46ce-a1fc-f10829e4f59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\srile\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98c772cc-7340-41ba-a1db-2d9e7396a625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up PyWSD (takes ~10 secs)... took 7.682044506072998 secs.\n"
     ]
    }
   ],
   "source": [
    "from pywsd.utils import lemmatize_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "216ab414-2c03-4be6-a7c3-0a49aad63af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\srile\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14fe1409-973d-4eb7-90af-064fe5fa150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k in range(df.shape[0]):\n",
    "    df.at[k,\"words\"]=list(\"\")\n",
    "    for j in range(len(df.loc[k,\"sentences\"])):\n",
    "        df.at[k,\"words\"].extend(lemmatize_sentence(df.loc[k,\"sentences\"][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "046baf2c-bbdb-46f4-9e93-812fd6acfa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"words_sentences\"] = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82607636-fa0e-4544-876b-074bb4f18cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is commonly used for tasks like memoization, partial function application, and modifying function properties.\n",
    "import functools\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for k in range(df.shape[0]):\n",
    "    words = df.loc[k, \"words\"]\n",
    "    # Check if words is empty and handle accordingly\n",
    "    if words:\n",
    "        # Join the words into a single string\n",
    "        df.loc[k, \"words_sentences\"] = functools.reduce(lambda a, b: str(a) + \" \" + str(b), words)\n",
    "    else:\n",
    "        # If the list is empty, set the column to an empty string or some default value\n",
    "        df.loc[k, \"words_sentences\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec74eef-ce25-4bda-9265-7ffa02c22b10",
   "metadata": {},
   "source": [
    "## Importing TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd08d928-4385-4654-95cd-bafef1efe1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f39b6cb-2bdd-4224-b2f7-9eda5c851d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BaseEstimator',\n",
       " 'CountVectorizer',\n",
       " 'ENGLISH_STOP_WORDS',\n",
       " 'FLOAT_DTYPES',\n",
       " 'FeatureHasher',\n",
       " 'HasMethods',\n",
       " 'HashingVectorizer',\n",
       " 'Integral',\n",
       " 'Interval',\n",
       " 'Mapping',\n",
       " 'NotFittedError',\n",
       " 'OneToOneFeatureMixin',\n",
       " 'RealNotInt',\n",
       " 'StrOptions',\n",
       " 'TfidfTransformer',\n",
       " 'TfidfVectorizer',\n",
       " 'TransformerMixin',\n",
       " '_IS_32BIT',\n",
       " '_VectorizerMixin',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_analyze',\n",
       " '_check_stop_list',\n",
       " '_document_frequency',\n",
       " '_fit_context',\n",
       " '_make_int_array',\n",
       " '_preprocess',\n",
       " 'array',\n",
       " 'check_array',\n",
       " 'check_is_fitted',\n",
       " 'defaultdict',\n",
       " 'itemgetter',\n",
       " 'normalize',\n",
       " 'np',\n",
       " 'partial',\n",
       " 're',\n",
       " 'sp',\n",
       " 'strip_accents_ascii',\n",
       " 'strip_accents_unicode',\n",
       " 'strip_tags',\n",
       " 'unicodedata',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.feature_extraction.text\n",
    "dir(sklearn.feature_extraction.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c35c8c02-85e7-4893-8ece-29b03322672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df.words_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf58c7e5-9368-4b3f-990c-9747a3f18a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = pd.DataFrame(tfidf_matrix.todense(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "df_y=df[\"verified\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe1398-36c4-4bbb-a66b-50c726eb9104",
   "metadata": {},
   "source": [
    "## Importing LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92c5ea82-29be-431f-85ca-82d8962905af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4da7ffa3-cfe4-4f47-b198-65be9f654c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "606e389e-4e30-459d-9c75-756c152c9211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_1=pd.DataFrame(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a799d5b3-808a-4329-8efe-865d93722fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_enc=df_y_1.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f833d22-3856-4ee1-8769-5eed7fbd8402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   verified\n",
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_enc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6c11b21-4320-4564-9d8a-2f33546f54e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 64.15%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "rf.fit(dense, df_y_enc)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_rf = rf.score(dense, df_y_enc)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a27edfe-4aa8-4ff3-be73-c8f1c2b7edd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 63.64%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(dense, df_y_enc)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy_nb = nb.score(dense, df_y_enc)\n",
    "print(f\"Naive Bayes Accuracy: {accuracy_nb * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1098d923-8a90-4b23-ad32-9e30afec10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6149e59-9969-46d4-b699-3c7bba8b15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC=GradientBoostingClassifier(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6de34054-fa3b-4abb-b976-21f0f7698895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "gb_c = GBC.fit(dense, df_y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8740444-e775-441f-ab81-565e01532a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbc_score: 64.15%\n"
     ]
    }
   ],
   "source": [
    "gbc_score=GBC.score(dense, df_y_enc)\n",
    "print(f\"gbc_score: {gbc_score* 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
